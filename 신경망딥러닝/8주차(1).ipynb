{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8주차(1).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCGkgueBSEVfpjx6GBmxmW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yYqJjoceQ0OP"},"outputs":[],"source":["# 고속 옵티마이저(최적화)"]},{"cell_type":"code","source":["# 표준적인 경사 하강법"],"metadata":{"id":"ZqO9I3DpR4gn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모멘텀 최적화\n","# 이전 그레디언트 중시"],"metadata":{"id":"xOPo2LTfR5Sv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 네스테로프 가속 경사(NAG)\n","# 모멘텀 최적화 개선\n","# 현재 위치가 아닌 모멘텀 방향으로 조금 가서 그레디언트 계산"],"metadata":{"id":"loaubxmcckW2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AdaGrad\n","# 가장 가파른 차원을 따라 그래디언트 벡터의 스케일을 감소"],"metadata":{"id":"Fsf9hVgdcwm9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# RMSProp\n","# AdaGrad가 최적점에 도착하기 전에 알고리즘이 멈추는 문제 해결\n","# 가장 최근 반복에서 비롯된 그래디언트만 누적"],"metadata":{"id":"G4kqM1mOc5Oc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adam\n","# 모멘텀 최적화의 가속과 RMSProp의 감쇠 아이디어를 합친 것"],"metadata":{"id":"UbzvoNtndC-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adamax\n","# Adam은 시간에 따라 감쇠된 그래디언트의 𝑙_2 norm으로 파라미터 업데이트의 스케일을 낮춘다\n","\n","# Nadam\n","# Adam + 네스테로프 가속 경사(NAG)\n","# 현재 위치에서 다음 위치로 이동할 기울기와 모 멘텀 값을 구하는 것이 아닌 \n","# 모멘텀 값으로 이동한 뒤에 기울기를 구하는 방식이다. \n"],"metadata":{"id":"Pa0GO4YRdMcc"},"execution_count":null,"outputs":[]}]}