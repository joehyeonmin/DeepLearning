{"cells":[{"cell_type":"markdown","metadata":{"id":"ArOjRcYF1iJV"},"source":["# Simple MNIST convnet\n","\n","원본 출처<br>\n","**Author:** [fchollet](https://twitter.com/fchollet)<br>\n","**Date created:** 2015/06/19<br>\n","**Last modified:** 2020/04/21<br>\n","**Description:** A simple convnet that achieves ~99% test accuracy on MNIST."]},{"cell_type":"markdown","source":["상단 메뉴 런타임 - 런타임 유형 변경에서 **GPU**를 선택하고 진행하세요."],"metadata":{"id":"vwLA7xE9Pq8N"}},{"cell_type":"markdown","metadata":{"id":"45H8fP9Y1iJY"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jdgsqtqJ1iJY"},"outputs":[],"source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","metadata":{"id":"Wa5mXEAT1iJZ"},"source":["## TODO 1: Feature scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EukNZ4871iJZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648193652459,"user_tz":-540,"elapsed":1557,"user":{"displayName":"조현민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13701119480392953941"}},"outputId":"0ba36126-a7fe-4121-ac38-a748ee5488d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}],"source":["# Model / data parameters\n","num_classes = 10            # 레이블의 개수 (0, 1, 2, ..., 9, 10개) \n","input_shape = (28, 28, 1)   # CNN은 2차원 정보를 활용합니다. (28 x 28 이미지 흑백 한 장, 기존 MLP는 784개의 픽셀 색상을 사용)\n","\n","# the data, split between train and test sets\n","# x를 이미지, y를 이미지에 대한 레이블로 표현합니다.\n","# x_train[0]은 첫 번째 훈련 그림, y_train[0]은 첫 번째 훈련 그림의 정답 ([0, 9]에 속한 숫자 하나)\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","\n","# 각 픽셀 값을 [0, 255] -> [0, 1]로 변환하세요.\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test = x_test.astype(\"float32\") / 255.0"]},{"cell_type":"markdown","source":["## TODO 2: Input shape"],"metadata":{"id":"YWnoMeIYTcnD"}},{"cell_type":"code","source":["# 현재 이미지의 shape을 출력하세요. (6만장의 28 x 28 이미지)\n","x_train.shape"],"metadata":{"id":"5RTLJgz5RBJ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648193652815,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13701119480392953941"}},"outputId":"4295e42a-ec03-4256-bfcd-4e363893ee37"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## TODO 3: Shape expanding"],"metadata":{"id":"wJ3L-zu1TjFW"}},{"cell_type":"code","source":["# Make sure images have shape (28, 28, 1) \n","# CNN은 한 장의 이미지 모양을 (가로, 세로, 채널 수)로 만들어야 합니다.\n","# 컬러 이미지는 R, G, B 세 장의 채널이지만 MNIST는 흑백이라 한 장의 채널이 필요합니다.\n","# 최종적으로 6만장의 28 x 28 이미지 흑백 채널 하나가 필요합니다.\n","# 가장 마지막 자리에 차원 하나 늘리기: (60000, 28, 28) -> (60000, 28, 28, 1)\n","\n","# expand_dims는 NumPy 배열의 특정 위치에 차원을 늘려줍니다.\n","# 파이썬에서 인덱싱할 때 가장 마지막 위치를 나타내는 정수를 기입하세요.\n","x_train = np.expand_dims(x_train, -1)\n","x_test = np.expand_dims(x_test, -1)\n","\n","print(\"x_train shape:\", x_train.shape)\n","print(\"x_test:\", x_test.shape)\n","print(x_train.shape[0], \"train samples\")\n","print(x_test.shape[0], \"test samples\")"],"metadata":{"id":"QdQuL31jQuPG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648193654492,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13701119480392953941"}},"outputId":"5be62545-1666-40e9-df1b-eab44ee5ea17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (60000, 28, 28, 1)\n","x_test: (10000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n"]}]},{"cell_type":"markdown","source":["## TODO 4: One-hot encoding"],"metadata":{"id":"7YDOg526TxtI"}},{"cell_type":"code","source":["# convert class vectors to binary class matrices (레이블을 범주형 인자로 변환)\n","from tensorflow.keras.utils import to_categorical\n","\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"metadata":{"id":"mCkCBG6nTsJK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5crne86l1iJa"},"source":["## Build the model"]},{"cell_type":"code","source":["model = keras.Sequential(\n","    [\n","        keras.Input(shape=input_shape),\n","        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2, 2)),\n","        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2, 2)),\n","        layers.Flatten(),   # MLP와 같이 데이터를 1차원 배열로 만듦\n","        layers.Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")\n","\n","model.summary()"],"metadata":{"id":"cHowQ6H2KQ7T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648193672664,"user_tz":-540,"elapsed":2809,"user":{"displayName":"조현민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13701119480392953941"}},"outputId":"45c3dd7f-c0c4-475b-fe5d-7042cc2c8fa6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 1600)              0         \n","                                                                 \n"," dense (Dense)               (None, 10)                16010     \n","                                                                 \n","=================================================================\n","Total params: 34,826\n","Trainable params: 34,826\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["##TODO 5: Model training"],"metadata":{"id":"wVtff9FzUzLW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8l6slYJ1iJc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648193708289,"user_tz":-540,"elapsed":33448,"user":{"displayName":"조현민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13701119480392953941"}},"outputId":"866b7184-79cb-4452-e6ab-2f2409f53870"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","422/422 [==============================] - 13s 6ms/step - loss: 0.2918 - accuracy: 0.9203 - val_loss: 0.0808 - val_accuracy: 0.9773\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0700 - val_accuracy: 0.9797\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0571 - accuracy: 0.9827 - val_loss: 0.0457 - val_accuracy: 0.9870\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0463 - accuracy: 0.9856 - val_loss: 0.0419 - val_accuracy: 0.9885\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.0445 - val_accuracy: 0.9890\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0387 - val_accuracy: 0.9902\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9906 - val_loss: 0.0461 - val_accuracy: 0.9875\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.0425 - val_accuracy: 0.9880\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0448 - val_accuracy: 0.9882\n","Epoch 10/10\n","422/422 [==============================] - 2s 6ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0406 - val_accuracy: 0.9898\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5ff016dc90>"]},"metadata":{},"execution_count":7}],"source":["batch_size = 128\n","epochs = 10\n","\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# 훈련 데이터의 10%는 사용하지 않고 남겨두었다가 Epoch이 끝날 때마다 남겨둔 데이터로 성능을 평가하여 출력해보세요.\n","# 따로 테스트를 하지 않더라도 테스트 했을 때의 성능을 짐작할 수 있게 도와줍니다.\n","# Hint: https://keras.io/api/models/model_training_apis/ 에서 fit method 참조\n","model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"]},{"cell_type":"markdown","metadata":{"id":"mBq6ZYNk1iJc"},"source":["## Evaluate the trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3MiZmVp71iJc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648193722995,"user_tz":-540,"elapsed":1626,"user":{"displayName":"조현민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13701119480392953941"}},"outputId":"818d5df7-c60b-4838-e32d-edc9b98490a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.03385036811232567\n","Test accuracy: 0.9884999990463257\n"]}],"source":["score = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"]},{"cell_type":"markdown","source":["## 이미지 변환 함수 (PNG -> 정규화된 일차원 배열)"],"metadata":{"id":"egTB_N2wVre6"}},{"cell_type":"code","source":["# image_prepare(파일이름)으로 호출하면 정규화된 일차원 리스트를 반환합니다.\n","\n","from PIL import Image, ImageFilter\n","\n","def image_prepare(argv):\n","    \"\"\"\n","    This function returns the pixel values.\n","    The imput is a png file location.\n","    \"\"\"\n","    im = Image.open(argv).convert('L')\n","    width = float(im.size[0])\n","    height = float(im.size[1])\n","    newImage = Image.new('L', (28, 28), (255))  # creates white canvas of 28x28 pixels\n","\n","    if width > height:  # check which dimension is bigger\n","        # Width is bigger. Width becomes 20 pixels.\n","        nheight = int(round((20.0 / width * height), 0))  # resize height according to ratio width\n","        if (nheight == 0):  # rare case but minimum is 1 pixel\n","            nheight = 1\n","            # resize and sharpen\n","        img = im.resize((20, nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n","        wtop = int(round(((28 - nheight) / 2), 0))  # calculate horizontal position\n","        newImage.paste(img, (4, wtop))  # paste resized image on white canvas\n","    else:\n","        # Height is bigger. Heigth becomes 20 pixels.\n","        nwidth = int(round((20.0 / height * width), 0))  # resize width according to ratio height\n","        if (nwidth == 0):  # rare case but minimum is 1 pixel\n","            nwidth = 1\n","            # resize and sharpen\n","        img = im.resize((nwidth, 20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n","        wleft = int(round(((28 - nwidth) / 2), 0))  # caculate vertical pozition\n","        newImage.paste(img, (wleft, 4))  # paste resized image on white canvas\n","\n","    # newImage.save(\"sample.png\n","\n","    tv = list(newImage.getdata())  # get pixel values\n","\n","    # normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n","    tva = [(255 - x) * 1.0 / 255.0 for x in tv]\n","    return tva"],"metadata":{"id":"SJIvHHMF6sA4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TODO 6: 지난 시간에 여러분이 그린 PNG 파일 변환\n","Colab으로 0.png ~ 9.png를 복사한 후 진행하세요."],"metadata":{"id":"AxovfB3oWDbc"}},{"cell_type":"code","source":["# 10장의 28 x 28 크기, 흑백 1채널\n","img_array = np.empty((10,28,28,1))\n","\n","for i in range(10):\n","  # 리스트를 NumPy 배열로 변환\n","  img = np.array(image_prepare(f'{i}.png'))\n","  # (784, ) -> (28, 28, 1)\n","  img_array[i] = img.reshape(28, 28, 1)"],"metadata":{"id":"3YK47PmO6wLr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TODO 7: 여러분의 PNG 파일 예측<br>\n","잘 예측되나요?"],"metadata":{"id":"iNbHa0qIci6n"}},{"cell_type":"code","source":["res = model.predict(img_array)\n","for r in res:\n","  # 값이 가장 큰 인덱스 출력하기 \n","  print(np.argmax(r))"],"metadata":{"id":"6rNvMkdS69Ov","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648193748104,"user_tz":-540,"elapsed":364,"user":{"displayName":"조현민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13701119480392953941"}},"outputId":"33a80a9b-e413-4598-dcd0-36b9829526f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","9\n","5\n","6\n","7\n","9\n","9\n"]}]},{"cell_type":"code","source":["# 80%"],"metadata":{"id":"x5PnUo7p94ej"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"KW_DLLAB_2022_04_MNIST_ConvNet_조현민_.ipynb의 사본","provenance":[{"file_id":"1e78AwWsbAacX4OQbrxxlNppLId4PASOU","timestamp":1648188290751},{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/mnist_convnet.ipynb","timestamp":1647761524901}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}